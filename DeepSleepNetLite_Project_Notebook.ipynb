{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ead31d9",
   "metadata": {},
   "source": [
    "# DeepSleepNet-Lite: Reproduction & Student Extensions\n",
    "\n",
    "**Fill your names here**  \n",
    "**Course:** cs584 f25 â€“ Final Project  \n",
    "**Generated:** 2025-11-03 19:18\n",
    "\n",
    "> This notebook reproduces a light, two-branch 1D CNN for single-channel EEG sleep staging (sequence-to-epoch with 90 seconds of context) and adds:\n",
    "> - Uniform and structured label smoothing\n",
    "> - Monte Carlo Dropout uncertainty\n",
    "> - Proper evaluation: Accuracy, Macro-F1, Weighted-F1, Cohen's kappa\n",
    "> - Calibration via ECE and reliability diagrams\n",
    "> - Selective prediction (reject the least-confident q%)  \n",
    "> All comments target students: we explain *what*, *why*, and *how* in practical terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19bfa8",
   "metadata": {},
   "source": [
    "## 0. Environment & Reproducibility\n",
    "We install/verify packages, print versions, and set seeds. If internet installs are blocked on your machine, pre-install the listed packages and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, importlib, os, random, json, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, cohen_kappa_score\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import mne\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a9ad3",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "Centralized hyper-parameters and paths. The entire notebook reads from this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7d1a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'sleep-edf',\n",
       " 'target_channel': 'Fpz-Cz',\n",
       " 'epoch_seconds': 30,\n",
       " 'context_epochs': 3,\n",
       " 'fs': 100,\n",
       " 'use_in_bed_only': False,\n",
       " 'cv_folds': 5,\n",
       " 'val_ratio': 0.1,\n",
       " 'seed': 42,\n",
       " 'batch_size': 128,\n",
       " 'max_epochs': 25,\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 0.001,\n",
       " 'patience': 5,\n",
       " 'device': 'cpu',\n",
       " 'small_kernel': 7,\n",
       " 'large_kernel': 49,\n",
       " 'n_filters': 64,\n",
       " 'dropout_p': 0.5,\n",
       " 'label_smoothing': 'uniform',\n",
       " 'ls_alpha': 0.1,\n",
       " 'mc_dropout_samples': 30,\n",
       " 'balance_strategy': 'oversample_and_flip',\n",
       " 'num_workers': 2,\n",
       " 'artifacts_dir': 'artifacts'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"dataset\": \"sleep-edf\",\n",
    "    \"target_channel\": \"Fpz-Cz\",\n",
    "    \"epoch_seconds\": 30,\n",
    "    \"context_epochs\": 3,             # 90 seconds = 3 x 30s\n",
    "    \"fs\": 100,\n",
    "    \"use_in_bed_only\": False,\n",
    "\n",
    "    \"cv_folds\": 5,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"seed\": 42,\n",
    "\n",
    "    \"batch_size\": 128,\n",
    "    \"max_epochs\": 25,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"patience\": 5,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    "    \"small_kernel\": 7,\n",
    "    \"large_kernel\": 49,\n",
    "    \"n_filters\": 64,\n",
    "    \"dropout_p\": 0.5,\n",
    "\n",
    "    \"label_smoothing\": \"uniform\",    # \"none\" | \"uniform\" | \"structured\"\n",
    "    \"ls_alpha\": 0.1,\n",
    "\n",
    "    \"mc_dropout_samples\": 30,\n",
    "    \"balance_strategy\": \"oversample_and_flip\",\n",
    "    \"num_workers\": 2,\n",
    "\n",
    "    \"artifacts_dir\": \"artifacts\", # select directory for artifacts\n",
    "}\n",
    "os.makedirs(CONFIG[\"artifacts_dir\"], exist_ok=True)\n",
    "with open(os.path.join(CONFIG[\"artifacts_dir\"], \"config.json\"), \"w\") as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f244e",
   "metadata": {},
   "source": [
    "## 2. Dataset handling\n",
    "We target Sleep-EDF (Fpz-Cz @ 100 Hz). To keep the notebook runnable everywhere, we provide a **synthetic fallback** if EDF files are not present or cannot be downloaded. Replace the fallback with real parsing for your full results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c59bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: (2400, 3000) Labels: (2400,) Subjects: (2400,)\n",
      "Balanced windows: (5390, 9000) Labels: (5390,)\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = os.path.join(CONFIG[\"artifacts_dir\"], \"sleep_edf\")\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "STAGE_MAP = {\"W\":0,\"N1\":1,\"N2\":2,\"N3\":3,\"R\":4}\n",
    "IDX2STAGE = {v:k for k,v in STAGE_MAP.items()}\n",
    "\n",
    "# def build_synthetic_dataset(n_subjects=4, epochs_per_subject=600, fs=100, epoch_sec=30):\n",
    "#     rng = np.random.default_rng(CONFIG[\"seed\"])\n",
    "#     X, y, subj = [], [], []\n",
    "#     for s in range(n_subjects):\n",
    "#         stages = rng.choice([0,1,2,3,4], size=epochs_per_subject, p=[0.2,0.1,0.45,0.15,0.1])\n",
    "#         samples = fs*epoch_sec\n",
    "#         signal = rng.normal(0, 1, size=(epochs_per_subject, samples))\n",
    "#         X.append(signal); y.append(stages); subj += [f\"SYN{s:02d}\"]*epochs_per_subject\n",
    "#     return np.vstack(X), np.hstack(y), np.array(subj)\n",
    "\n",
    "# For the template we use synthetic data so the rest of the pipeline is executable.\n",
    "# X_epochs, y_epochs, subjects = build_synthetic_dataset()\n",
    "# print(\"Epochs:\", X_epochs.shape, \"Labels:\", y_epochs.shape, \"Subjects:\", subjects.shape)\n",
    "\n",
    "def build_context_windows(Xe, ye, sub, context_epochs=3):\n",
    "    assert context_epochs == 3\n",
    "    Xw, yw, sw = [], [], []\n",
    "    for i in range(1, len(ye)-1):\n",
    "        win = np.concatenate([Xe[i-1], Xe[i], Xe[i+1]], axis=0)\n",
    "        Xw.append(win); yw.append(ye[i]); sw.append(sub[i])\n",
    "    Xw = np.vstack([np.array(x)[None,:] for x in Xw])\n",
    "    return Xw.astype(np.float32), np.array(yw).astype(np.int64), np.array(sw)\n",
    "\n",
    "# ===== Replace synthetic dataset with real Sleep-EDF parsing (MNE) =====\n",
    "# This cell requires that you have the EDF files under DATA_ROOT\n",
    "#   e.g., artifacts/sleep_edf/sleep-cassette/SC4001E0-PSG.edf\n",
    "#         artifacts/sleep_edf/sleep-cassette/SC4001EC-Hypnogram.edf\n",
    "# If you already downloaded the full Sleep-EDF (2018), point DATA_ROOT accordingly.\n",
    "\n",
    "import mne, os, glob, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "FS_TARGET = CONFIG[\"fs\"]                 # 100 Hz\n",
    "EPOCH_SEC = CONFIG[\"epoch_seconds\"]      # 30 s\n",
    "USE_IN_BED_ONLY = CONFIG[\"use_in_bed_only\"]\n",
    "\n",
    "# Map MNE annotation labels to 5 classes {W, N1, N2, N3, R}\n",
    "def stage_label_to_int(desc: str):\n",
    "    # Typical MNE descriptions: \"Sleep stage W\", \"Sleep stage 1\", \"Sleep stage 2\",\n",
    "    # \"Sleep stage 3\", \"Sleep stage 4\", \"Sleep stage R\", \"Sleep stage ?\",\n",
    "    # sometimes \"Movement time\".\n",
    "    d = (desc or \"\").strip().upper()\n",
    "    if \"SLEEP STAGE W\" in d:\n",
    "        return 0  # W\n",
    "    if \"SLEEP STAGE R\" in d:\n",
    "        return 4  # REM\n",
    "    if \"SLEEP STAGE 1\" in d:\n",
    "        return 1  # N1\n",
    "    if \"SLEEP STAGE 2\" in d:\n",
    "        return 2  # N2\n",
    "    if \"SLEEP STAGE 3\" in d or \"SLEEP STAGE 4\" in d:\n",
    "        return 3  # N3 (merge N3+N4)\n",
    "    # ignore movement or unknown\n",
    "    return None\n",
    "\n",
    "def find_psg_hyp_pairs(root):\n",
    "    \"\"\"Return list of (psg_path, hyp_path).\"\"\"\n",
    "    root = Path(root)\n",
    "    # Sleep-EDF (2018) layout often includes subdir 'sleep-cassette'\n",
    "    psgs = sorted(glob.glob(str(root / \"sleep-cassette\" / \"*-PSG.edf\")))\n",
    "    pairs = []\n",
    "    for psg in psgs:\n",
    "        hyp = psg.replace(\"-PSG.edf\", \"C-Hypnogram.edf\")\n",
    "        if not os.path.exists(hyp):\n",
    "            # Some releases use slightly different suffix; try broader search\n",
    "            base = os.path.basename(psg).split(\"-PSG.edf\")[0]\n",
    "            cand = glob.glob(str(Path(psg).parent / f\"{base}Hypnogram.edf\"))\n",
    "            if cand:\n",
    "                hyp = cand[0]\n",
    "        if os.path.exists(hyp):\n",
    "            pairs.append((psg, hyp))\n",
    "    return pairs\n",
    "\n",
    "def pick_fpz_cz_channel(raw: mne.io.BaseRaw):\n",
    "    \"\"\"Pick Fpz-Cz channel (or the closest match). Returns channel name.\"\"\"\n",
    "    chs = [ch.upper() for ch in raw.ch_names]\n",
    "    # exact or partial matches\n",
    "    for key in [\"EEG Fpz-Cz\", \"FPZ-CZ\", \"EEG FPZ-CZ\", \"FPZCZ\", \"FPZ-CZ\"]:\n",
    "        for orig in raw.ch_names:\n",
    "            if key == orig.upper():\n",
    "                return orig\n",
    "    # heuristic partial search\n",
    "    for orig in raw.ch_names:\n",
    "        u = orig.upper()\n",
    "        if \"FPZ\" in u and \"CZ\" in u:\n",
    "            return orig\n",
    "    # fallback: first EEG channel\n",
    "    picks = mne.pick_types(raw.info, eeg=True, eog=False, emg=False)\n",
    "    if len(picks) == 0:\n",
    "        raise RuntimeError(\"No EEG channel found in this record.\")\n",
    "    return raw.ch_names[picks[0]]\n",
    "\n",
    "def get_lights_on_off(annotations: mne.Annotations):\n",
    "    \"\"\"Return (lights_off_time_sec, lights_on_time_sec) if present; else (None,None).\"\"\"\n",
    "    lo, li = None, None\n",
    "    for onset, duration, desc in zip(annotations.onset, annotations.duration, annotations.description):\n",
    "        d = (desc or \"\").lower()\n",
    "        if \"lights off\" in d and lo is None:\n",
    "            lo = onset\n",
    "        if \"lights on\" in d and li is None:\n",
    "            li = onset\n",
    "    return lo, li\n",
    "\n",
    "def extract_epochs_from_record(psg_path, hyp_path, fs_target=100, epoch_sec=30, use_in_bed_only=False):\n",
    "    \"\"\"Return X_epochs [N, fs*epoch_sec], y_epochs [N], subject_id [N].\"\"\"\n",
    "    # Load raw PSG\n",
    "    raw = mne.io.read_raw_edf(psg_path, preload=True, verbose=\"ERROR\")\n",
    "    # Read hypnogram annotations\n",
    "    hyp = mne.read_annotations(hyp_path)\n",
    "    raw.set_annotations(hyp)  # attach hypnogram to raw timeline\n",
    "\n",
    "    # Pick Fpz-Cz (or best match) and resample to fs_target if needed\n",
    "    ch = pick_fpz_cz_channel(raw)\n",
    "    raw.pick_channels([ch])\n",
    "    if abs(raw.info[\"sfreq\"] - fs_target) > 1e-6:\n",
    "        raw.resample(fs_target)\n",
    "\n",
    "    # Determine time window: full or in-bed only\n",
    "    tmin, tmax = 0.0, raw.times[-1]\n",
    "    if use_in_bed_only:\n",
    "        lo, li = get_lights_on_off(raw.annotations)\n",
    "        if lo is not None and li is not None and li > lo:\n",
    "            tmin, tmax = lo, li\n",
    "\n",
    "    # Build 30s epochs grid\n",
    "    n_samples_epoch = int(fs_target * epoch_sec)\n",
    "    start_sample = int(tmin * fs_target)\n",
    "    end_sample   = int(tmax * fs_target)\n",
    "    # Align to epoch boundary\n",
    "    start_sample = (start_sample // n_samples_epoch) * n_samples_epoch\n",
    "    end_sample   = (end_sample   // n_samples_epoch) * n_samples_epoch\n",
    "\n",
    "    # Prepare a fast label lookup from annotations\n",
    "    # For each epoch, we take the label at the epoch midpoint\n",
    "    labels = []\n",
    "    X = []\n",
    "    for s0 in range(start_sample, end_sample, n_samples_epoch):\n",
    "        s1 = s0 + n_samples_epoch\n",
    "        mid_time = (s0 + s1) / 2.0 / fs_target  # seconds\n",
    "\n",
    "        # Find annotation active at mid_time\n",
    "        lab = None\n",
    "        for onset, duration, desc in zip(raw.annotations.onset, raw.annotations.duration, raw.annotations.description):\n",
    "            if onset <= mid_time < onset + duration:\n",
    "                lab = stage_label_to_int(desc)\n",
    "                break\n",
    "\n",
    "        if lab is None:\n",
    "            # Unknown or movement time -> skip this epoch\n",
    "            continue\n",
    "\n",
    "        # Extract data for this epoch and z-score normalize per-epoch\n",
    "        x = raw.get_data(start=s0, stop=s1)[0]  # channel already picked -> shape [T]\n",
    "        mu, sd = x.mean(), x.std() + 1e-8\n",
    "        x = (x - mu) / sd\n",
    "\n",
    "        X.append(x.astype(np.float32))\n",
    "        labels.append(lab)\n",
    "\n",
    "    X = np.stack(X, axis=0) if len(X) else np.empty((0, n_samples_epoch), dtype=np.float32)\n",
    "    y = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # Subject id from filename prefix (e.g., SC4001E0)\n",
    "    sid = os.path.basename(psg_path).split(\"-\")[0]\n",
    "    subj = np.array([sid] * len(y))\n",
    "    return X, y, subj\n",
    "\n",
    "# ---- Load all pairs ----\n",
    "pairs = find_psg_hyp_pairs(DATA_ROOT)\n",
    "if not pairs:\n",
    "    raise RuntimeError(\n",
    "        f\"No PSG/Hypnogram pairs found under {DATA_ROOT}. \"\n",
    "        f\"Place Sleep-EDF files (sleep-cassette/*-PSG.edf and *-Hypnogram.edf) there.\"\n",
    "    )\n",
    "\n",
    "X_list, y_list, s_list = [], [], []\n",
    "for psg, hyp in pairs:\n",
    "    Xi, yi, si = extract_epochs_from_record(\n",
    "        psg, hyp, fs_target=FS_TARGET, epoch_sec=EPOCH_SEC, use_in_bed_only=USE_IN_BED_ONLY\n",
    "    )\n",
    "    if len(yi) == 0:\n",
    "        print(f\"[WARN] No labeled epochs from {psg} (after filtering). Skipping.\")\n",
    "        continue\n",
    "    X_list.append(Xi); y_list.append(yi); s_list.append(si)\n",
    "\n",
    "X_epochs = np.concatenate(X_list, axis=0)\n",
    "y_epochs = np.concatenate(y_list, axis=0)\n",
    "subjects = np.concatenate(s_list, axis=0)\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "print(\"Loaded real Sleep-EDF epochs:\", X_epochs.shape, \"labels:\", y_epochs.shape, \"subjects:\", subjects.shape)\n",
    "\n",
    "X_win, y_win, subj_win = build_context_windows(X_epochs, y_epochs, subjects, CONFIG[\"context_epochs\"])\n",
    "\n",
    "def balance_data(X, y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    max_c = counts.max()\n",
    "    Xb, yb = [], []\n",
    "    rng = np.random.default_rng(CONFIG[\"seed\"])\n",
    "    for c in classes:\n",
    "        idx = np.where(y == c)[0]\n",
    "        Xi, yi = X[idx], y[idx]\n",
    "        Xi_aug = np.concatenate([Xi, -Xi], axis=0)\n",
    "        yi_aug = np.concatenate([yi, yi], axis=0)\n",
    "        if len(Xi_aug) < max_c:\n",
    "            extra = rng.choice(len(Xi_aug), size=max_c-len(Xi_aug), replace=True)\n",
    "            Xi_aug = np.concatenate([Xi_aug, Xi_aug[extra]], axis=0)\n",
    "            yi_aug = np.concatenate([yi_aug, yi_aug[extra]], axis=0)\n",
    "        else:\n",
    "            Xi_aug = Xi_aug[:max_c]; yi_aug = yi_aug[:max_c]\n",
    "        Xb.append(Xi_aug); yb.append(yi_aug)\n",
    "    Xb = np.concatenate(Xb, axis=0); yb = np.concatenate(yb, axis=0)\n",
    "    perm = rng.permutation(len(yb))\n",
    "    return Xb[perm], yb[perm]\n",
    "\n",
    "if CONFIG[\"balance_strategy\"] == \"oversample_and_flip\":\n",
    "    X_bal, y_bal = balance_data(X_win, y_win)\n",
    "else:\n",
    "    X_bal, y_bal = X_win, y_win\n",
    "\n",
    "print(\"Balanced windows:\", X_bal.shape, \"Labels:\", y_bal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510816c8",
   "metadata": {},
   "source": [
    "## 3. Model: two-branch 1D CNN (DeepSleepNet-Lite style)\n",
    "Small kernels capture fine temporal features; large kernels capture broader spectral context. We keep parameter count modest and avoid RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f130b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    # Conv1d -> BN -> ReLU -> MaxPool\n",
    "    def __init__(self, in_ch, out_ch, k, pool=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_ch, out_ch, kernel_size=k, padding=k//2)\n",
    "        self.bn = nn.BatchNorm1d(out_ch, eps=1e-5, momentum=0.999)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool1d(pool)\n",
    "    def forward(self, x):\n",
    "        return self.pool(self.act(self.bn(self.conv(x))))\n",
    "\n",
    "class DeepSleepNetLite(nn.Module):\n",
    "    # Input: [B, 1, T]; Output: class logits for 5 stages\n",
    "    def __init__(self, n_classes=5, nf=64, k_small=7, k_large=49, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.s1 = ConvBlock(1, nf, k_small)\n",
    "        self.s2 = ConvBlock(nf, nf, k_small)\n",
    "        self.s3 = ConvBlock(nf, 2*nf, k_small)\n",
    "        self.s4 = ConvBlock(2*nf, 2*nf, k_small)\n",
    "\n",
    "        self.l1 = ConvBlock(1, nf, k_large)\n",
    "        self.l2 = ConvBlock(nf, nf, k_large)\n",
    "        self.l3 = ConvBlock(nf, 2*nf, k_large)\n",
    "        self.l4 = ConvBlock(2*nf, 2*nf, k_large)\n",
    "\n",
    "        self.drop = nn.Dropout(p_drop)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*nf, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = self.s4(self.s3(self.s2(self.s1(x))))\n",
    "        xl = self.l4(self.l3(self.l2(self.l1(x))))\n",
    "        xcat = torch.cat([xs, xl], dim=1)\n",
    "        xcat = self.drop(xcat)\n",
    "        return self.head(xcat)\n",
    "\n",
    "# Simple shape check\n",
    "tmp = torch.randn(2,1,CONFIG[\"fs\"]*CONFIG[\"epoch_seconds\"]*CONFIG[\"context_epochs\"])\n",
    "print(\"Logits shape:\", DeepSleepNetLite().forward(tmp).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaee213",
   "metadata": {},
   "source": [
    "## 4. Label smoothing\n",
    "Uniform (LSu) mixes one-hot with uniform; structured (LSs) mixes one-hot with an empirical transition-based distribution M(prev,:,next) estimated from training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uniform_targets(y, n_classes=5, alpha=0.1, device=\"cpu\"):\n",
    "    off = alpha / n_classes\n",
    "    on = 1.0 - alpha + off\n",
    "    tgt = torch.full((len(y), n_classes), off, dtype=torch.float32, device=device)\n",
    "    tgt[torch.arange(len(y)), y] = on\n",
    "    return tgt\n",
    "\n",
    "def estimate_M_structured(y_sequence, n_classes=5):\n",
    "    M = np.ones((n_classes, n_classes, n_classes), dtype=np.float64)  # Laplace smoothing\n",
    "    for i in range(1, len(y_sequence)-1):\n",
    "        p, c, n = y_sequence[i-1], y_sequence[i], y_sequence[i+1]\n",
    "        M[p, c, n] += 1.0\n",
    "    # normalize over middle dimension\n",
    "    M = M / M.sum(axis=1, keepdims=True)\n",
    "    M = M / M.sum(axis=2, keepdims=True)\n",
    "    return M\n",
    "\n",
    "def make_structured_targets(y, y_prev, y_next, M, alpha=0.2, n_classes=5, device=\"cpu\"):\n",
    "    B = len(y)\n",
    "    tgt = torch.zeros((B, n_classes), dtype=torch.float32, device=device)\n",
    "    for i in range(B):\n",
    "        vec = torch.tensor(M[y_prev[i].item(), :, y_next[i].item()], dtype=torch.float32, device=device)\n",
    "        vec = vec / (vec.sum() + 1e-8)\n",
    "        tgt[i] = (1.0 - alpha) * F.one_hot(y[i], n_classes).float() + alpha * vec\n",
    "    return tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d56ef3",
   "metadata": {},
   "source": [
    "## 5. Dataset wrapper and CV splits (by subject)\n",
    "We wrap arrays into a Dataset that also carries prev/next labels for LSs, and create subject-wise folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3027afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folds (subjects): [[np.str_('SYN03')], [np.str_('SYN02')], [np.str_('SYN01')], [np.str_('SYN00')], []]\n"
     ]
    }
   ],
   "source": [
    "class SleepWindows(Dataset):\n",
    "    def __init__(self, X, y, subj, prev_labels, next_labels):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.subj = np.array(subj)\n",
    "        self.prev = prev_labels.astype(np.int64)\n",
    "        self.next = next_labels.astype(np.int64)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx][None, :]  # [1, T]\n",
    "        return x, self.y[idx], self.prev[idx], self.next[idx]\n",
    "\n",
    "prev_arr = np.concatenate([[y_bal[0]], y_bal[:-1]])\n",
    "next_arr = np.concatenate([y_bal[1:], [y_bal[-1]]])\n",
    "dataset = SleepWindows(X_bal, y_bal, subj_win[:len(y_bal)], prev_arr, next_arr)\n",
    "\n",
    "uniq_subj = sorted(list(set(dataset.subj)))\n",
    "rng = np.random.default_rng(CONFIG[\"seed\"])\n",
    "rng.shuffle(uniq_subj)\n",
    "folds = np.array_split(uniq_subj, CONFIG[\"cv_folds\"])\n",
    "print(\"Folds (subjects):\", [list(f) for f in folds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e2588",
   "metadata": {},
   "source": [
    "## 6. Utilities: Early stopping, ECE, reliability plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f418de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece_score(confidences, correctness, n_bins=15):\n",
    "    bins = np.linspace(0., 1., n_bins+1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        sel = (confidences > lo) & (confidences <= hi)\n",
    "        if sel.sum() == 0: continue\n",
    "        acc = correctness[sel].mean()\n",
    "        conf = confidences[sel].mean()\n",
    "        ece += (sel.sum() / len(confidences)) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def plot_reliability(confidences, correctness, n_bins=15):\n",
    "    bins = np.linspace(0., 1., n_bins+1)\n",
    "    xs, ys = [], []\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        sel = (confidences > lo) & (confidences <= hi)\n",
    "        if sel.sum() == 0: continue\n",
    "        xs.append(correctness[sel].mean()); ys.append(confidences[sel].mean())\n",
    "    plt.figure()\n",
    "    plt.plot([0,1],[0,1],'--', linewidth=1)\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.xlabel(\"Accuracy per bin\"); plt.ylabel(\"Mean confidence per bin\"); plt.title(\"Reliability Diagram\")\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5):\n",
    "        self.best = None; self.wait = 0; self.pat = patience; self.state=None\n",
    "    def step(self, metric, model):\n",
    "        if self.best is None or metric > self.best:\n",
    "            self.best = metric; self.wait = 0\n",
    "            self.state = {k:v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "            return False\n",
    "        self.wait += 1\n",
    "        return self.wait > self.pat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ee73c",
   "metadata": {},
   "source": [
    "## 7. Train per fold\n",
    "We train with the selected label smoothing strategy and early stopping on macro-F1 (more robust to class imbalance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fd0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_for_fold(fold_id):\n",
    "    test_subj = set(folds[fold_id])\n",
    "    train_subj = set().union(*[set(f) for i,f in enumerate(folds) if i!=fold_id])\n",
    "    train_mask = np.array([s in train_subj for s in dataset.subj])\n",
    "    test_mask  = np.array([s in test_subj  for s in dataset.subj])\n",
    "    idx_train_all = np.where(train_mask)[0]\n",
    "    idx_test = np.where(test_mask)[0]\n",
    "    rng = np.random.default_rng(CONFIG[\"seed\"] + fold_id)\n",
    "    perm = rng.permutation(len(idx_train_all))\n",
    "    n_val = max(1, int(CONFIG[\"val_ratio\"] * len(idx_train_all)))\n",
    "    idx_val = idx_train_all[perm[:n_val]]\n",
    "    idx_train = idx_train_all[perm[n_val:]]\n",
    "    return idx_train, idx_val, idx_test\n",
    "\n",
    "def run_fold(train_idx, val_idx, test_idx, data):\n",
    "    set_seeds(CONFIG[\"seed\"])\n",
    "    device = CONFIG[\"device\"]\n",
    "    model = DeepSleepNetLite(nf=CONFIG[\"n_filters\"],\n",
    "                             k_small=CONFIG[\"small_kernel\"],\n",
    "                             k_large=CONFIG[\"large_kernel\"],\n",
    "                             p_drop=CONFIG[\"dropout_p\"]).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "\n",
    "    def make_loader(idxs, shuffle):\n",
    "        subset = torch.utils.data.Subset(data, idxs.tolist())\n",
    "        return DataLoader(subset, batch_size=CONFIG[\"batch_size\"], shuffle=shuffle,\n",
    "                          num_workers=CONFIG[\"num_workers\"], drop_last=False)\n",
    "\n",
    "    train_loader = make_loader(train_idx, True)\n",
    "    val_loader   = make_loader(val_idx, False)\n",
    "\n",
    "    M = estimate_M_structured(data.y[train_idx]) if CONFIG[\"label_smoothing\"] == \"structured\" else None\n",
    "    stopper = EarlyStopper(CONFIG[\"patience\"])\n",
    "    history = []\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(1, CONFIG[\"max_epochs\"]+1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for xb, yb, pb, nb in train_loader:\n",
    "            xb, yb, pb, nb = xb.to(device), yb.to(device), pb.to(device), nb.to(device)\n",
    "            logits = model(xb)\n",
    "            if CONFIG[\"label_smoothing\"] == \"uniform\":\n",
    "                targets = make_uniform_targets(yb, n_classes=5, alpha=CONFIG[\"ls_alpha\"], device=device)\n",
    "                loss = -(targets * F.log_softmax(logits, dim=1)).sum(dim=1).mean()\n",
    "            elif CONFIG[\"label_smoothing\"] == \"structured\":\n",
    "                targets = make_structured_targets(yb, pb, nb, M, alpha=CONFIG[\"ls_alpha\"], device=device)\n",
    "                loss = -(targets * F.log_softmax(logits, dim=1)).sum(dim=1).mean()\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits, yb)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred, y_conf = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _, _ in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                probs = F.softmax(model(xb), dim=1)\n",
    "                conf, pred = probs.max(dim=1)\n",
    "                y_true.extend(yb.cpu().numpy()); y_pred.extend(pred.cpu().numpy()); y_conf.extend(conf.cpu().numpy())\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        mf1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "        wf1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        ece = ece_score(np.array(y_conf), (np.array(y_true)==np.array(y_pred)).astype(float))\n",
    "        history.append({\"epoch\":epoch,\"loss\":float(np.mean(losses)),\"acc\":acc,\"mf1\":mf1,\"wf1\":wf1,\"kappa\":kappa,\"ece\":ece})\n",
    "        print(f\"Epoch {epoch:02d} | loss {np.mean(losses):.4f} | acc {acc:.3f} | MF1 {mf1:.3f} | k {kappa:.3f} | ECE {ece:.3f}\")\n",
    "        if stopper.step(mf1, model):\n",
    "            print(\"Early stopping\"); break\n",
    "        else:\n",
    "            best_epoch = epoch\n",
    "\n",
    "    model.load_state_dict(stopper.state)\n",
    "    return model, pd.DataFrame(history), best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262afdf",
   "metadata": {},
   "source": [
    "## 8. Run K-fold CV, save models and histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d8361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Fold 0 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn=== Fold\u001b[39m\u001b[38;5;124m\"\u001b[39m, fid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m tr, va, te \u001b[38;5;241m=\u001b[39m indices_for_fold(fid)\n\u001b[0;32m----> 6\u001b[0m model, hist, best_ep \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mte\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifacts_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), save_path)\n",
      "Cell \u001b[0;32mIn[12], line 42\u001b[0m, in \u001b[0;36mrun_fold\u001b[0;34m(train_idx, val_idx, test_idx, data)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb, pb, nb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     41\u001b[0m     xb, yb, pb, nb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device), pb\u001b[38;5;241m.\u001b[39mto(device), nb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 42\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_smoothing\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m         targets \u001b[38;5;241m=\u001b[39m make_uniform_targets(yb, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, alpha\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls_alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 37\u001b[0m, in \u001b[0;36mDeepSleepNetLite.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms1(x))))\n\u001b[0;32m---> 37\u001b[0m     xl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml4(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml3\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     38\u001b[0m     xcat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([xs, xl], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m     xcat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(xcat)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/pooling.py:146\u001b[0m, in \u001b[0;36mMaxPool1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_jit_internal.py:627\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:733\u001b[0m, in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ALL = []\n",
    "FOLD_RESULTS = []\n",
    "for fid in range(len(folds)):\n",
    "    print(\"\\\\n=== Fold\", fid, \"===\")\n",
    "    tr, va, te = indices_for_fold(fid)\n",
    "    model, hist, best_ep = run_fold(tr, va, te, dataset)\n",
    "    save_path = os.path.join(CONFIG[\"artifacts_dir\"], f\"model_fold{fid}.pt\")\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    hist.to_csv(os.path.join(CONFIG[\"artifacts_dir\"], f\"history_fold{fid}.csv\"), index=False)\n",
    "    FOLD_RESULTS.append({\"fold\": fid, \"best_epoch\": int(best_ep), \"model_path\": save_path})\n",
    "pd.DataFrame(FOLD_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a6146",
   "metadata": {},
   "source": [
    "## 9. Test evaluation + MC Dropout + Selective prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_mc_dropout(m):\n",
    "    for module in m.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.train()\n",
    "\n",
    "def evaluate_model(model, idxs, mc_samples=0):\n",
    "    device = CONFIG[\"device\"]\n",
    "    loader = DataLoader(torch.utils.data.Subset(dataset, idxs.tolist()),\n",
    "                        batch_size=CONFIG[\"batch_size\"], shuffle=False,\n",
    "                        num_workers=CONFIG[\"num_workers\"], drop_last=False)\n",
    "    y_true, y_pred, y_conf = [], [], []\n",
    "    if mc_samples <= 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _, _ in loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                probs = F.softmax(model(xb), dim=1)\n",
    "                conf, pred = probs.max(dim=1)\n",
    "                y_true.extend(yb.cpu().numpy()); y_pred.extend(pred.cpu().numpy()); y_conf.extend(conf.cpu().numpy())\n",
    "        return np.array(y_true), np.array(y_pred), np.array(y_conf)\n",
    "    else:\n",
    "        model.eval(); enable_mc_dropout(model)\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, _, _ in loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                probs_mc = []\n",
    "                for _ in range(mc_samples):\n",
    "                    probs_mc.append(F.softmax(model(xb), dim=1).unsqueeze(0))\n",
    "                probs_mc = torch.cat(probs_mc, dim=0)\n",
    "                probs = probs_mc.mean(dim=0)\n",
    "                conf, pred = probs.max(dim=1)\n",
    "                y_true.extend(yb.cpu().numpy()); y_pred.extend(pred.cpu().numpy()); y_conf.extend(conf.cpu().numpy())\n",
    "        return np.array(y_true), np.array(y_pred), np.array(y_conf)\n",
    "\n",
    "ALL_METRICS = []\n",
    "for rec in FOLD_RESULTS:\n",
    "    fid = rec[\"fold\"]\n",
    "    _, _, idx_test = indices_for_fold(fid)\n",
    "\n",
    "    model = DeepSleepNetLite(nf=CONFIG[\"n_filters\"],\n",
    "                             k_small=CONFIG[\"small_kernel\"],\n",
    "                             k_large=CONFIG[\"large_kernel\"],\n",
    "                             p_drop=CONFIG[\"dropout_p\"]).to(CONFIG[\"device\"])\n",
    "    model.load_state_dict(torch.load(rec[\"model_path\"], map_location=CONFIG[\"device\"]))\n",
    "\n",
    "    y_t, y_p, y_c = evaluate_model(model, idx_test, mc_samples=0)\n",
    "    acc = accuracy_score(y_t, y_p); mf1 = f1_score(y_t, y_p, average=\"macro\")\n",
    "    wf1 = f1_score(y_t, y_p, average=\"weighted\"); kappa = cohen_kappa_score(y_t, y_p)\n",
    "    ece = ece_score(y_c, (y_t==y_p).astype(float))\n",
    "    print(f\"[Fold {fid}] TEST std: acc {acc:.3f} mf1 {mf1:.3f} k {kappa:.3f} ece {ece:.3f}\")\n",
    "    ALL_METRICS.append({\"fold\":fid,\"mode\":\"standard\",\"acc\":acc,\"mf1\":mf1,\"wf1\":wf1,\"kappa\":kappa,\"ece\":ece})\n",
    "    plot_reliability(y_c, (y_t==y_p).astype(float))\n",
    "\n",
    "    S = CONFIG[\"mc_dropout_samples\"]\n",
    "    y_t2, y_p2, y_c2 = evaluate_model(model, idx_test, mc_samples=S)\n",
    "    acc2 = accuracy_score(y_t2, y_p2); mf1_2 = f1_score(y_t2, y_p2, average=\"macro\")\n",
    "    wf1_2 = f1_score(y_t2, y_p2, average=\"weighted\"); kappa2 = cohen_kappa_score(y_t2, y_p2)\n",
    "    ece2 = ece_score(y_c2, (y_t2==y_p2).astype(float))\n",
    "    print(f\"[Fold {fid}] TEST MC{S}: acc {acc2:.3f} mf1 {mf1_2:.3f} k {kappa2:.3f} ece {ece2:.3f}\")\n",
    "    ALL_METRICS.append({\"fold\":fid,\"mode\":f\"mc{S}\",\"acc\":acc2,\"mf1\":mf1_2,\"wf1\":wf1_2,\"kappa\":kappa2,\"ece\":ece2})\n",
    "\n",
    "    for q in [0.05, 0.1, 0.2]:\n",
    "        thr = np.quantile(y_c2, q)\n",
    "        mask = y_c2 > thr\n",
    "        if mask.sum()==0: continue\n",
    "        acc_q = accuracy_score(y_t2[mask], y_p2[mask])\n",
    "        mf1_q = f1_score(y_t2[mask], y_p2[mask], average=\"macro\")\n",
    "        kappa_q = cohen_kappa_score(y_t2[mask], y_p2[mask])\n",
    "        print(f\"[Fold {fid}] MC{S} reject {int(q*100)}%: acc {acc_q:.3f} mf1 {mf1_q:.3f} k {kappa_q:.3f}\")\n",
    "        ALL_METRICS.append({\"fold\":fid,\"mode\":f\"mc{S}_reject_{int(q*100)}\",\"acc\":acc_q,\"mf1\":mf1_q,\"wf1\":None,\"kappa\":kappa_q,\"ece\":None})\n",
    "\n",
    "pd.DataFrame(ALL_METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d62911",
   "metadata": {},
   "source": [
    "## 10. Qualitative inspection\n",
    "We show a couple of sample windows with predicted distribution (mean if MC) to understand errors and uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(model, idxs, n=2, mc_samples=0):\n",
    "    device = CONFIG[\"device\"]\n",
    "    loader = DataLoader(torch.utils.data.Subset(dataset, idxs.tolist()[:n]), batch_size=1, shuffle=False)\n",
    "    model.eval()\n",
    "    if mc_samples>0:\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Dropout): m.train()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, _, _ in loader:\n",
    "            xb = xb.to(device); gt = int(yb.item())\n",
    "            if mc_samples>0:\n",
    "                pm = []\n",
    "                for _ in range(mc_samples):\n",
    "                    pm.append(F.softmax(model(xb), dim=1).cpu().numpy()[0])\n",
    "                probs = np.mean(pm, axis=0)\n",
    "            else:\n",
    "                probs = F.softmax(model(xb), dim=1).cpu().numpy()[0]\n",
    "            pred = int(np.argmax(probs))\n",
    "            plt.figure(); plt.plot(xb.cpu().numpy().ravel()); plt.title(f\"True {IDX2STAGE[gt]} | Pred {IDX2STAGE[pred]} | Conf {probs[pred]:.2f}\")\n",
    "            plt.figure(); plt.bar(range(5), probs); plt.xticks(range(5), [IDX2STAGE[i] for i in range(5)]); plt.title(\"Predicted probabilities\")\n",
    "\n",
    "_, _, idx_test0 = indices_for_fold(0)\n",
    "m0 = DeepSleepNetLite(nf=CONFIG[\"n_filters\"], k_small=CONFIG[\"small_kernel\"], k_large=CONFIG[\"large_kernel\"], p_drop=CONFIG[\"dropout_p\"]).to(CONFIG[\"device\"])\n",
    "m0.load_state_dict(torch.load(os.path.join(CONFIG[\"artifacts_dir\"], \"model_fold0.pt\"), map_location=CONFIG[\"device\"]))\n",
    "show_examples(m0, idx_test0, n=2, mc_samples=CONFIG[\"mc_dropout_samples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0e295",
   "metadata": {},
   "source": [
    "## 11. Export artifacts for final submission\n",
    "We save metrics, a minimal `model.txt`, `data.txt`, and a `requirements.txt` as requested by the brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = os.path.join(CONFIG[\"artifacts_dir\"], \"metrics.csv\")\n",
    "pd.DataFrame(ALL_METRICS).to_csv(metrics_path, index=False)\n",
    "print(\"Saved:\", metrics_path)\n",
    "\n",
    "with open(os.path.join(CONFIG[\"artifacts_dir\"], \"model.txt\"), \"w\") as f:\n",
    "    f.write(\"# Saved model weights (per fold)\\n\")\n",
    "    for rec in os.listdir(CONFIG[\"artifacts_dir\"]):\n",
    "        if rec.startswith(\"model_fold\") and rec.endswith(\".pt\"):\n",
    "            f.write(rec + \"\\n\")\n",
    "\n",
    "with open(os.path.join(CONFIG[\"artifacts_dir\"], \"data.txt\"), \"w\") as f:\n",
    "    f.write(\"Sleep-EDF Expanded (Sleep Cassette). PhysioNet.\\nPlace EDF files under artifacts/sleep_edf/ if auto-download is not available.\\n\")\n",
    "\n",
    "reqs = [\n",
    "    \"numpy\",\"scipy\",\"pandas\",\"matplotlib\",\"scikit-learn\",\n",
    "    \"torch==2.2.2\",\"torchmetrics>=1.3.0\",\"tqdm\",\"wfdb\",\"mne\"\n",
    "]\n",
    "with open(os.path.join(CONFIG[\"artifacts_dir\"], \"requirements.txt\"), \"w\") as f:\n",
    "    f.write(\"\\\\n\".join(reqs))\n",
    "\n",
    "print(\"Artifacts in:\", CONFIG[\"artifacts_dir\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
